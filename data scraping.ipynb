{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping data from Skytrax\n",
    "\n",
    "If you visit [https://www.airlinequality.com] you can see that there is a lot of data there. For this task, we are only interested in reviews related to British Airways and the Airline itself.\n",
    "\n",
    "If you navigate to this link: [https://www.airlinequality.com/airline-reviews/british-airways] you will see this data. Now, we can use `Python` and `BeautifulSoup` to collect all the links to the reviews and then to collect the text data on each of the individual review links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "recommendation = [] # 'yes' or 'no'\n",
    "country = []\n",
    "rating  = []        # 1-10  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "   ---> 100 total reviews\n",
      "Scraping page 2\n",
      "   ---> 200 total reviews\n",
      "Scraping page 3\n",
      "   ---> 300 total reviews\n",
      "Scraping page 4\n",
      "   ---> 400 total reviews\n",
      "Scraping page 5\n",
      "   ---> 500 total reviews\n",
      "Scraping page 6\n",
      "   ---> 600 total reviews\n",
      "Scraping page 7\n",
      "   ---> 700 total reviews\n",
      "Scraping page 8\n",
      "   ---> 800 total reviews\n",
      "Scraping page 9\n",
      "   ---> 900 total reviews\n",
      "Scraping page 10\n",
      "   ---> 1000 total reviews\n",
      "Scraping page 11\n",
      "   ---> 1100 total reviews\n",
      "Scraping page 12\n",
      "   ---> 1200 total reviews\n",
      "Scraping page 13\n",
      "   ---> 1300 total reviews\n",
      "Scraping page 14\n",
      "   ---> 1400 total reviews\n",
      "Scraping page 15\n",
      "   ---> 1500 total reviews\n",
      "Scraping page 16\n",
      "   ---> 1600 total reviews\n",
      "Scraping page 17\n",
      "   ---> 1700 total reviews\n",
      "Scraping page 18\n",
      "   ---> 1800 total reviews\n",
      "Scraping page 19\n",
      "   ---> 1900 total reviews\n",
      "Scraping page 20\n",
      "   ---> 2000 total reviews\n",
      "Scraping page 21\n",
      "   ---> 2100 total reviews\n",
      "Scraping page 22\n",
      "   ---> 2200 total reviews\n",
      "Scraping page 23\n",
      "   ---> 2300 total reviews\n",
      "Scraping page 24\n",
      "   ---> 2400 total reviews\n",
      "Scraping page 25\n",
      "   ---> 2500 total reviews\n",
      "Scraping page 26\n",
      "   ---> 2600 total reviews\n",
      "Scraping page 27\n",
      "   ---> 2700 total reviews\n",
      "Scraping page 28\n",
      "   ---> 2800 total reviews\n",
      "Scraping page 29\n",
      "Error on page 29\n",
      "   ---> 2900 total reviews\n",
      "Scraping page 30\n",
      "   ---> 3000 total reviews\n",
      "Scraping page 31\n",
      "Error on page 31\n",
      "Error on page 31\n",
      "   ---> 3100 total reviews\n",
      "Scraping page 32\n",
      "   ---> 3200 total reviews\n",
      "Scraping page 33\n",
      "Error on page 33\n",
      "Error on page 33\n",
      "   ---> 3300 total reviews\n",
      "Scraping page 34\n",
      "Error on page 34\n",
      "   ---> 3400 total reviews\n",
      "Scraping page 35\n",
      "   ---> 3461 total reviews\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "pages = 35          # pagingation\n",
    "page_size = 100     # how many max-reviews in each page   \n",
    "\n",
    "\n",
    "for i in range(1, pages + 1):\n",
    "\n",
    "    print(f\"Scraping page {i}\")\n",
    "\n",
    "    # Create URL to collect links from paginated data\n",
    "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    # Collect HTML data from this page\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse content\n",
    "    content = response.content\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    for item in soup.find_all(\"div\", {\"class\": \"text_content\"}):\n",
    "        reviews.append(item.get_text())\n",
    "\n",
    "    #country\n",
    "    for item in soup.find_all(\"h3\"):\n",
    "        country.append(item.span.next_sibling.text.strip(\" ()\"))\n",
    "\n",
    "    for item in soup.find_all(\"td\", {\"class\": {\"review-value rating-yes\", \"review-value rating-no\"}}):\n",
    "        recommendation.append(item.get_text())\n",
    "\n",
    "    for item in soup.find_all(\"div\", class_ = \"rating-10\"):\n",
    "        try:\n",
    "            rating.append(item.span.text)\n",
    "        except:\n",
    "            print(f\"Error on page {i}\")\n",
    "            rating.append(\"None\")\n",
    "    \n",
    "    print(f\"   ---> {len(reviews)} total reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'âœ… Trip Verified |  This flight was one of the worst I have ever had in my life. I wanted to pamper myself, so I bought business class. I was looking forward to my new experience. I will not mention the chaos of changing gates several times, as these things may happen. What surprised me was the lack of attention to passengers. The flight was delayed by almost 3 hours. Even though staff offered vouchers, we had no idea where to get them, and we were told that we only had about 10 minutes to use them because boarding had already begun. Firstly, I did not see anyone with the voucher, and secondly, even if we got it, we were not able to use it. When I finally got to the airport, there was another waiting for about 30 minutes after cross check. Meantime, we were told that due to problems, they did not load any food, so the flight will be without any food on board. The only food offered and given to everyone on the plane was a small bag of nuts. As a business class passenger, I was offered drinks only. All in all, my business class contained 3 small glasses of juice. \\xa0 I received no apology or compensation from the company at all. It was a disgraceful and cheap service for a very expensive price. '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(reviews))\n",
    "reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['no', 'no', 'no', 'yes', 'yes']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(recommendation))\n",
    "recommendation[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['United Kingdom',\n",
       " 'United States',\n",
       " 'United Kingdom',\n",
       " 'United Kingdom',\n",
       " 'United Kingdom']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(country))\n",
    "country[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5', '2', '3', '2', '9']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(rating))\n",
    "rating[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually there are only 3461 reviews of users but we are here having 3496 `ratings` becoz while we scrapped the `ratings` from each page, our code actually scraps 1 extra `Overall Rating` placed on the above of each pagination page. So we are having more no. of ratings than it should be(here it is 3496 instead of 3461), the rating having `\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t` in front is actually the overall rating, so we'll drop those unwanted overall rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = [ x for x in rating if \"\\t\" not in x ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3461"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rating)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all the columns have same number of data i.e.3461."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Country</th>\n",
       "      <th>Recommended</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>âœ… Trip Verified |  This flight was one of the ...</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not Verified | It seems that there is a race t...</td>\n",
       "      <td>United States</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not Verified |  As a Spanish born individual l...</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>âœ… Trip Verified |  A rather empty and quiet fl...</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>yes</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>âœ… Trip Verified |  Easy check in and staff mem...</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>yes</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews         Country  \\\n",
       "0  âœ… Trip Verified |  This flight was one of the ...  United Kingdom   \n",
       "1  Not Verified | It seems that there is a race t...   United States   \n",
       "2  Not Verified |  As a Spanish born individual l...  United Kingdom   \n",
       "3  âœ… Trip Verified |  A rather empty and quiet fl...  United Kingdom   \n",
       "4  âœ… Trip Verified |  Easy check in and staff mem...  United Kingdom   \n",
       "\n",
       "  Recommended Rating  \n",
       "0          no      2  \n",
       "1          no      3  \n",
       "2          no      2  \n",
       "3         yes      9  \n",
       "4         yes      9  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Reviews':reviews, 'Country':country, 'Recommended':recommendation, 'Rating':rating})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/BA_reviews.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fbc768028c3e6ead51d9a200ddcb2ec858ae62844dcd1994729a8279be9b48f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
